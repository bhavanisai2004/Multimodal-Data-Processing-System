{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42897110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-generativeai in c:\\users\\user\\anaconda3\\lib\\site-packages (0.3.2)\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.1)\n",
      "Requirement already satisfied: python-docx in c:\\users\\user\\anaconda3\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: python-pptx in c:\\users\\user\\anaconda3\\lib\\site-packages (0.6.23)\n",
      "Requirement already satisfied: pytube in c:\\users\\user\\anaconda3\\lib\\site-packages (15.0.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (10.1.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: google-auth in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (2.35.0)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (2.28.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (4.12.2)\n",
      "Requirement already satisfied: protobuf in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (4.25.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-generativeai) (4.65.0)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.4.0->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: lxml>=3.1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-docx) (4.9.3)\n",
      "Requirement already satisfied: XlsxWriter>=0.5.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-pptx) (3.2.9)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (2.31.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-auth->google-generativeai) (4.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.62.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth->google-generativeai) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2023.7.22)\n",
      "\n",
      "✅ Installation complete!\n",
      "⚠️ NOW GO TO: Kernel → Restart\n",
      "Then run CELL 2\n"
     ]
    }
   ],
   "source": [
    "!pip install google-generativeai PyPDF2 python-docx python-pptx pytube pillow\n",
    "\n",
    "print(\"\\n✅ Installation complete!\")\n",
    "print(\"⚠️ NOW GO TO: Kernel → Restart\")\n",
    "print(\"Then run CELL 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c79dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All imports successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import PyPDF2\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "from PIL import Image\n",
    "import google.generativeai as genai\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b68b8bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-gecko-001\n",
      "models/gemini-2.5-pro-preview-03-25\n",
      "models/gemini-2.5-flash-preview-05-20\n",
      "models/gemini-2.5-flash\n",
      "models/gemini-2.5-flash-lite-preview-06-17\n",
      "models/gemini-2.5-pro-preview-05-06\n",
      "models/gemini-2.5-pro-preview-06-05\n",
      "models/gemini-2.5-pro\n",
      "models/gemini-2.0-flash-exp\n",
      "models/gemini-2.0-flash\n",
      "models/gemini-2.0-flash-001\n",
      "models/gemini-2.0-flash-exp-image-generation\n",
      "models/gemini-2.0-flash-lite-001\n",
      "models/gemini-2.0-flash-lite\n",
      "models/gemini-2.0-flash-preview-image-generation\n",
      "models/gemini-2.0-flash-lite-preview-02-05\n",
      "models/gemini-2.0-flash-lite-preview\n",
      "models/gemini-2.0-pro-exp\n",
      "models/gemini-2.0-pro-exp-02-05\n",
      "models/gemini-exp-1206\n",
      "models/gemini-2.0-flash-thinking-exp-01-21\n",
      "models/gemini-2.0-flash-thinking-exp\n",
      "models/gemini-2.0-flash-thinking-exp-1219\n",
      "models/gemini-2.5-flash-preview-tts\n",
      "models/gemini-2.5-pro-preview-tts\n",
      "models/learnlm-2.0-flash-experimental\n",
      "models/gemma-3-1b-it\n",
      "models/gemma-3-4b-it\n",
      "models/gemma-3-12b-it\n",
      "models/gemma-3-27b-it\n",
      "models/gemma-3n-e4b-it\n",
      "models/gemma-3n-e2b-it\n",
      "models/gemini-flash-latest\n",
      "models/gemini-flash-lite-latest\n",
      "models/gemini-pro-latest\n",
      "models/gemini-2.5-flash-lite\n",
      "models/gemini-2.5-flash-image-preview\n",
      "models/gemini-2.5-flash-image\n",
      "models/gemini-2.5-flash-preview-09-2025\n",
      "models/gemini-2.5-flash-lite-preview-09-2025\n",
      "models/gemini-robotics-er-1.5-preview\n",
      "models/gemini-2.5-computer-use-preview-10-2025\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "models/aqa\n",
      "models/imagen-3.0-generate-002\n",
      "models/imagen-4.0-generate-preview-06-06\n",
      "models/imagen-4.0-ultra-generate-preview-06-06\n",
      "models/imagen-4.0-generate-001\n",
      "models/imagen-4.0-ultra-generate-001\n",
      "models/imagen-4.0-fast-generate-001\n",
      "models/veo-2.0-generate-001\n",
      "models/veo-3.0-generate-preview\n",
      "models/veo-3.0-fast-generate-preview\n",
      "models/veo-3.0-generate-001\n",
      "models/veo-3.0-fast-generate-001\n",
      "models/veo-3.1-generate-preview\n",
      "models/veo-3.1-fast-generate-preview\n",
      "models/gemini-2.0-flash-live-001\n",
      "models/gemini-live-2.5-flash-preview\n",
      "models/gemini-2.5-flash-live-preview\n",
      "models/gemini-2.5-flash-native-audio-latest\n",
      "models/gemini-2.5-flash-native-audio-preview-09-2025\n"
     ]
    }
   ],
   "source": [
    "#pip install -U google-generativeai\n",
    "\n",
    "#import google.generativeai as genai\n",
    "#GEMINI_API_KEY = \"AIzaSyBmRtKZ5yvqVLyhsHFWcdUPyrZXcRYSWPQ\"\n",
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyBmRtKZ5yvqVLyhsHFWcdUPyrZXcRYSWPQ\")\n",
    "\n",
    "for m in genai.list_models():\n",
    "    print(m.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fb4f119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there! Thanks for asking, and for the specific shout-out.\n",
      "\n",
      "As an AI, I don't have feelings or a \"day\" in the human sense, but I can tell you that all my systems are running optimally. My language models are humming along, my data is freshly indexed, and I'm ready and eager to help.\n",
      "\n",
      "So, in a way, you could say I'm doing great!\n",
      "\n",
      "What's on your mind today? Is there something I can help you learn, create, or figure out?\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# ✅ Configure your key\n",
    "genai.configure(api_key=\"AIzaSyBmRtKZ5yvqVLyhsHFWcdUPyrZXcRYSWPQ\")\n",
    "\n",
    "# ✅ Use a valid latest model\n",
    "model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n",
    "\n",
    "# ✅ Test prompt\n",
    "response = model.generate_content(\"Hello Gemini 2.5! How are you today?\")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239af582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Finding available Gemini 2.x model...\n",
      "✅ Found working model: models/gemini-2.5-pro\n",
      "Response: Hello there! It's great to hear from you.\n",
      "\n",
      "How can I help you today?\n",
      "✅ Using: models/gemini-2.5-pro\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "GEMINI_API_KEY = \"AIzaSyBmRtKZ5yvqVLyhsHFWcdUPyrZXcRYSWPQ\"\n",
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "print(\"🔍 Finding available Gemini 2.x model...\")\n",
    "working_model = None\n",
    "\n",
    "# ✅ Updated model list\n",
    "model_options = [\n",
    "    \"models/gemini-2.5-pro\",\n",
    "    \"models/gemini-2.5-flash\",\n",
    "    \"models/gemini-2.5-flash-lite\",\n",
    "]\n",
    "\n",
    "for model_name in model_options:\n",
    "    try:\n",
    "        test = genai.GenerativeModel(model_name)\n",
    "        response = test.generate_content(\"Hi Gemini!\")\n",
    "        print(f\"✅ Found working model: {model_name}\")\n",
    "        print(\"Response:\", response.text)\n",
    "        working_model = model_name\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"⏭️ {model_name} - {str(e)[:100]}\")\n",
    "\n",
    "if working_model:\n",
    "    model = genai.GenerativeModel(working_model)\n",
    "    vision_model = genai.GenerativeModel(working_model)\n",
    "    print(f\"✅ Using: {working_model}\")\n",
    "else:\n",
    "    print(\"❌ No working model found. Check your API key or model names.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e348ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Database ready!\n"
     ]
    }
   ],
   "source": [
    "class SimpleDatabase:\n",
    "    def __init__(self):\n",
    "        self.documents = []\n",
    "        self.all_text = \"\"\n",
    "    \n",
    "    def add(self, text, source):\n",
    "        self.documents.append({'text': text, 'source': source})\n",
    "        self.all_text += f\"\\n\\n========== {source} ==========\\n{text}\"\n",
    "    \n",
    "    def get_all_text(self):\n",
    "        return self.all_text\n",
    "    \n",
    "    def clear(self):\n",
    "        self.documents = []\n",
    "        self.all_text = \"\"\n",
    "    \n",
    "    def list_all(self):\n",
    "        if not self.documents:\n",
    "            return \"📭 No documents yet\"\n",
    "        output = \"\\n📚 STORED DOCUMENTS:\\n\" + \"=\"*70 + \"\\n\"\n",
    "        for i, doc in enumerate(self.documents, 1):\n",
    "            preview = doc['text'][:100].replace('\\n', ' ')\n",
    "            output += f\"{i}. {doc['source']} ({len(doc['text'])} chars)\\n   {preview}...\\n\\n\"\n",
    "        return output\n",
    "\n",
    "db = SimpleDatabase()\n",
    "print(\"✅ Database ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f92f7251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Files in Downloads:\n",
      "  📄 07461dac7a.pdf\n",
      "  📄 1-84fa5dab-ac32-41a7-9cf4-536e9fb237ed.pdf\n",
      "  📄 1000028676[1].jpg\n",
      "  📄 10th (1).pdf\n",
      "  📄 10th.pdf\n",
      "  📄 12th.pdf\n",
      "  📄 1st sem (2).pdf\n",
      "  📄 2103.14030v2 (2).pdf\n",
      "  📄 21R11A05C1.pdf\n",
      "  📄 2219976.jpg\n",
      "  📄 2nd sem.pdf\n",
      "  📄 3-2.pdf\n",
      "  📄 3rd sem.pdf\n",
      "  📄 4th sem.pdf\n",
      "  📄 5c1 Tech Seminar - Abstract.pdf\n",
      "  📄 5th sem.pdf\n",
      "  📄 623c6049370bc295635571_GET_JD___ERS_&_Digital_Business.pdf\n",
      "  📄 6th sem.pdf\n",
      "  📄 8th.pdf\n",
      "  📄 accelq certificate.jpg\n",
      "  📄 Accenture is a leading global professional services company that specializes in strategy.docx\n",
      "  📄 act.pdf\n",
      "  📄 addharcard.pdf\n",
      "  📄 AdmissionCard-14727125-438e7dc1-7d84-44c3-bc36-d81ceaae8701-742.pdf\n",
      "  📄 Admit card.pdf\n",
      "  📄 advanced java programming oracle.pdf\n",
      "  📄 AI (1).pdf\n",
      "  📄 AI-Driven Early Detection of Alzheimer's Disease Through Neuroimaging Analysis.pdf\n",
      "  📄 AI-Driven Early Detection of Alzheimer's Disease Through Neuroimaging.pptx\n",
      "  📄 AI-Driven.pptx\n",
      "  📄 AI_Impact_Presentation.pptx\n",
      "  📄 alzheimers-research-paper(1) (2).docx\n",
      "  📄 alzheimers-research-paper.pdf\n",
      "  📄 alzheimers_detection_madhu.txt\n",
      "  📄 alzheimers_detection_sai.txt\n",
      "  📄 alzheimers_detection_saibhavani (3).txt\n",
      "  📄 alzheimers_detection_saibhavani.txt\n",
      "  📄 Alzheimers_Disease_Detection_Presentation.pptx\n",
      "  📄 Application_form_HCLTFP1332096.pdf\n",
      "  📄 AWS_Academy_Graduate___AWS_Academy_Cloud_Foundations_Badge20241205-26-pshlzn (1).pdf\n",
      "  📄 AWS_Academy_Graduate___AWS_Academy_Cloud_Foundations_Badge20241205-26-pshlzn.pdf\n",
      "  📄 BA.pdf\n",
      "  📄 background.jpg\n",
      "  📄 batch c17 bhavani.docx\n",
      "  📄 batch c17.docx\n",
      "  📄 batch c17.pdf\n",
      "  📄 bhavani (1) - MAJOR[1] (1) (1).docx\n",
      "  📄 bhavani (1) - MAJOR[1].pdf\n",
      "  📄 bhavani.docx\n",
      "  📄 Bhavani.pdf\n",
      "  📄 bhavanii.pdf\n",
      "  📄 bhavanimajorF.docx\n",
      "  📄 BHAVANI_9182900487 (1) (1).pdf\n",
      "  📄 BHAVANI_9182900487 (1).docx\n",
      "  📄 BHAVANI_9182900487 (1).pdf\n",
      "  📄 bhavani_9182900487.pdf\n",
      "  📄 bhavani_RESUME (2) (1).pdf\n",
      "  📄 bhavani_RESUME (2).pdf\n",
      "  📄 Biometrics To Fight Credential Fraud.pptx\n",
      "  📄 book.pdf\n",
      "  📄 capdataanalyst.pdf\n",
      "  📄 capstone4 report.docx\n",
      "  📄 cgi.pdf\n",
      "  📄 cisco.pdf\n",
      "  📄 cmm Bhavani.pdf\n",
      "  📄 Collaborate Exit-NDA- Sandhya Rani Dasari.docx\n",
      "  📄 DasariSaiBhavaniResume.pdf\n",
      "  📄 del.pdf\n",
      "  📄 delan.pdf\n",
      "  📄 DocScanner 23 Nov 2024 7-52 pm.pdf\n",
      "  📄 DocScanner 30 Dec 2023 8-56 pm.pdf\n",
      "  📄 DT20245772770.pdf\n",
      "  📄 DT20245772770_Application.pdf\n",
      "  📄 e-EPIC_NYU2576973 (1).pdf\n",
      "  📄 e-EPIC_NYU2576973.pdf\n",
      "  📄 Exit-NoDue - Sandhya Rani Dasari.docx\n",
      "  📄 Id.pdf\n",
      "  📄 image.png\n",
      "  📄 IMG20230611185419.jpg\n",
      "  📄 IMG20230716125121.jpg\n",
      "  📄 IMG_20230625_184034.jpg\n",
      "  📄 info.txt\n",
      "  📄 java fundamentals oracle.pdf\n",
      "  📄 Java Interview - Preparation (1).pdf\n",
      "  📄 Java Interview - Preparation (2).pdf\n",
      "  📄 Java Interview - Preparation.pdf\n",
      "  📄 javafundamentals24 exam.pdf\n",
      "  📄 javafundamentalscoursecompletion.pdf\n",
      "  📄 javaprogrammingexam.pdf\n",
      "  📄 linkdlin.pdf\n",
      "  📄 maj_proj_update_1.docx\n",
      "  📄 mcqs and blanks-updated.docx\n",
      "  📄 memobtech.jpg\n",
      "  📄 mid2.exam.pdf\n",
      "  📄 mini project abstract format .docx\n",
      "  📄 mini project abstract format .pdf\n",
      "  📄 mini project abstract format.docx\n",
      "  📄 Mini project-Bhavani (1).docx\n",
      "  📄 Mini project-Bhavani (2).docx\n",
      "  📄 Mini project-Bhavani (3).docx\n",
      "  📄 Mini project-Bhavani (4).docx\n",
      "  📄 Mini project-Bhavani.docx\n",
      "  📄 Mini project-Bhavani.pdf\n",
      "  📄 Mini project.pdf\n",
      "  📄 miniprojectreport.pdf\n",
      "  📄 MLPBL.docx\n",
      "  📄 mlres.pdf\n",
      "  📄 Modern-Resume-Template.docx\n",
      "  📄 Monitors.docx\n",
      "  📄 MP report  (1).docx\n",
      "  📄 MS-word- new (1).docx\n",
      "  📄 MS-word- new.docx\n",
      "  📄 mymini.pdf\n",
      "  📄 New ms word.pdf\n",
      "  📄 notes.docx\n",
      "  📄 openart-3cc072b57d794fc7895aae22c602fbe0_raw.jpg\n",
      "  📄 optum.pdf\n",
      "  📄 oraclejavafudamentals.pdf\n",
      "  📄 pan.pdf\n",
      "  📄 pancard (1).pdf\n",
      "  📄 pancard.pdf\n",
      "  📄 paper.docx\n",
      "  📄 Parallel Programming in High.docx\n",
      "  📄 pasphotoo.jpg\n",
      "  📄 passphoto (1).pdf\n",
      "  📄 passphoto.pdf\n",
      "  📄 PBLApp_Login_Process_Usage_Guide_TNext_v2.pdf\n",
      "  📄 pcadmmin,+2.pdf\n",
      "  📄 photo.pdf\n",
      "  📄 Presentation major (1).pptx\n",
      "  📄 Presentation major.pptx\n",
      "  📄 Presentation(final).pptx\n",
      "  📄 princi.pdf\n",
      "  📄 PROJECT (1).pptx\n",
      "  📄 PROJECT.pptx\n",
      "  📄 qa.pdf\n",
      "  📄 Resume.pdf\n",
      "  📄 resumephoto.jpg\n",
      "  📄 rpap.docx\n",
      "  📄 rpap.pdf\n",
      "  📄 saibhavani.pdf\n",
      "  📄 saibhavaniii.pdf\n",
      "  📄 SaiBhavani_Dasari_9182900487.pdf\n",
      "  📄 sample.pdf\n",
      "  📄 sample_image.png\n",
      "  📄 sandhya btech memo.jpg\n",
      "  📄 sandhya pic.jpg\n",
      "  📄 Sandhya Rani .New (1).pdf\n",
      "  📄 Screenshot 2024-09-27 223724.png\n",
      "  📄 sde (1).pdf\n",
      "  📄 secret-org-00D5j00000DjS4t-data-ver-1.txt\n",
      "  📄 Setup and Data Preparation.docx\n",
      "  📄 Sheet 1.png\n",
      "  📄 slides.pptx\n",
      "  📄 sqa.pdf\n",
      "  📄 task1_new.pdf\n",
      "  📄 tcs form.pdf\n",
      "  📄 VA_Presentation.pptx\n",
      "  📄 vijaya paper.pdf\n",
      "  📄 Word Count (1).pdf\n",
      "  📄 xylem.pdf\n",
      "\n",
      "📄 Processing: sample.pdf\n",
      "✅ PDF: sample.pdf processed.\n",
      "\n",
      "📄 Processing: notes.docx\n",
      "✅ DOCX: notes.docx processed.\n",
      "\n",
      "📄 Processing: slides.pptx\n",
      "✅ PPTX: slides.pptx processed.\n",
      "\n",
      "📄 Processing: info.txt\n",
      "✅ TEXT: info.txt processed.\n",
      "\n",
      "📄 Processing: photo1.png\n",
      "❌ File not found: C:\\Users\\USER\\Downloads\\photo1.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "downloads = r\"C:\\Users\\USER\\Downloads\"\n",
    "\n",
    "files_to_process = [\n",
    "    (r\"C:\\Users\\USER\\Downloads\\sample.pdf\", \"pdf\"),\n",
    "    (r\"C:\\Users\\USER\\Downloads\\notes.docx\", \"docx\"),\n",
    "    (r\"C:\\Users\\USER\\Downloads\\slides.pptx\", \"pptx\"),\n",
    "    (r\"C:\\Users\\USER\\Downloads\\info.txt\", \"txt\"),\n",
    "    (r\"C:\\Users\\USER\\Downloads\\photo1.png\", \"image\"),  # ✅ Updated filename here\n",
    "]\n",
    "\n",
    "print(f\"\\nFiles in Downloads:\")\n",
    "for f in os.listdir(downloads):\n",
    "    if f.endswith(('.pdf', '.docx', '.pptx', '.txt', '.jpg', '.png')):\n",
    "        print(f\"  📄 {f}\")\n",
    "\n",
    "for file_path, ftype in files_to_process:\n",
    "    print(f\"\\n📄 Processing: {os.path.basename(file_path)}\")\n",
    "    if not os.path.exists(file_path):\n",
    "        print(f\"❌ File not found: {file_path}\")\n",
    "        continue\n",
    "\n",
    "    # Placeholder processing based on type\n",
    "    if ftype == \"pdf\":\n",
    "        print(f\"✅ PDF: {os.path.basename(file_path)} processed.\")\n",
    "    elif ftype == \"docx\":\n",
    "        print(f\"✅ DOCX: {os.path.basename(file_path)} processed.\")\n",
    "    elif ftype == \"pptx\":\n",
    "        print(f\"✅ PPTX: {os.path.basename(file_path)} processed.\")\n",
    "    elif ftype == \"txt\":\n",
    "        print(f\"✅ TEXT: {os.path.basename(file_path)} processed.\")\n",
    "    elif ftype == \"image\":\n",
    "        print(f\"✅ IMAGE: {os.path.basename(file_path)} processed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ac4b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: youtube-transcript-api in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "pip install youtube-transcript-api\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01372ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b98d887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytube in c:\\users\\user\\anaconda3\\lib\\site-packages (15.0.0)\n",
      "Requirement already satisfied: youtube-transcript-api in c:\\users\\user\\anaconda3\\lib\\site-packages (1.2.3)\n",
      "Requirement already satisfied: yt-dlp in c:\\users\\user\\anaconda3\\lib\\site-packages (2025.10.22)\n",
      "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from youtube-transcript-api) (0.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\lib\\site-packages (from youtube-transcript-api) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests->youtube-transcript-api) (2023.7.22)\n",
      "✅ Processor ready!\n",
      "\n",
      "🎉 SYSTEM READY!\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELL 4: CREATE PROCESSOR (FINAL VERSION)\n",
    "# ========================================\n",
    "\n",
    "!pip install pytube youtube-transcript-api yt-dlp\n",
    "\n",
    "import os\n",
    "import yt_dlp\n",
    "from docx import Document\n",
    "from pptx import Presentation\n",
    "from PIL import Image\n",
    "import PyPDF2\n",
    "from pytube import YouTube\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Assuming `db`, `model`, and `vision_model` are already defined in earlier cells.\n",
    "\n",
    "class MultimodalProcessor:\n",
    "    def __init__(self):\n",
    "        self.file_count = 0\n",
    "\n",
    "    # ------------------- PDF -------------------\n",
    "    def process_pdf(self, file_path):\n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                return f\"❌ File not found: {file_path}\"\n",
    "            \n",
    "            text = \"\"\n",
    "            with open(file_path, 'rb') as file:\n",
    "                reader = PyPDF2.PdfReader(file)\n",
    "                for page in reader.pages:\n",
    "                    text += page.extract_text() or \"\"\n",
    "            \n",
    "            if not text.strip():\n",
    "                return \"⚠️ No text found in PDF\"\n",
    "            \n",
    "            db.add(text, f\"PDF: {os.path.basename(file_path)}\")\n",
    "            self.file_count += 1\n",
    "            return f\"✅ Processed PDF: {os.path.basename(file_path)} ({len(text):,} chars)\"\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error processing PDF: {str(e)}\"\n",
    "\n",
    "    # ------------------- DOCX -------------------\n",
    "    def process_docx(self, file_path):\n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                return f\"❌ File not found: {file_path}\"\n",
    "            \n",
    "            doc = Document(file_path)\n",
    "            text = \"\\n\".join([p.text for p in doc.paragraphs if p.text.strip()])\n",
    "            if not text.strip():\n",
    "                return \"⚠️ No text in DOCX\"\n",
    "            \n",
    "            db.add(text, f\"DOCX: {os.path.basename(file_path)}\")\n",
    "            self.file_count += 1\n",
    "            return f\"✅ Processed DOCX: {os.path.basename(file_path)} ({len(text):,} chars)\"\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error processing DOCX: {str(e)}\"\n",
    "\n",
    "    # ------------------- PPTX -------------------\n",
    "    def process_pptx(self, file_path):\n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                return f\"❌ File not found: {file_path}\"\n",
    "            \n",
    "            prs = Presentation(file_path)\n",
    "            text = \"\"\n",
    "            for slide in prs.slides:\n",
    "                for shape in slide.shapes:\n",
    "                    if hasattr(shape, \"text\"):\n",
    "                        text += shape.text + \"\\n\"\n",
    "            \n",
    "            if not text.strip():\n",
    "                return \"⚠️ No text found in PPTX\"\n",
    "            \n",
    "            db.add(text, f\"PPTX: {os.path.basename(file_path)}\")\n",
    "            self.file_count += 1\n",
    "            return f\"✅ Processed PPTX: {os.path.basename(file_path)} ({len(text):,} chars)\"\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error processing PPTX: {str(e)}\"\n",
    "\n",
    "    # ------------------- TXT -------------------\n",
    "    def process_txt(self, file_path):\n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                return f\"❌ File not found: {file_path}\"\n",
    "            \n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                text = f.read()\n",
    "            \n",
    "            if not text.strip():\n",
    "                return \"⚠️ Empty TXT file\"\n",
    "            \n",
    "            db.add(text, f\"TXT: {os.path.basename(file_path)}\")\n",
    "            self.file_count += 1\n",
    "            return f\"✅ Processed TXT: {os.path.basename(file_path)} ({len(text):,} chars)\"\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error processing TXT: {str(e)}\"\n",
    "\n",
    "    # ------------------- IMAGE -------------------\n",
    "    def process_image(self, file_path):\n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                return f\"❌ File not found: {file_path}\"\n",
    "            \n",
    "            img = Image.open(file_path)\n",
    "            response = vision_model.generate_content([\n",
    "                \"Describe this image and extract all visible text:\",\n",
    "                img\n",
    "            ])\n",
    "            db.add(response.text, f\"IMAGE: {os.path.basename(file_path)}\")\n",
    "            self.file_count += 1\n",
    "            return f\"✅ Processed IMAGE: {os.path.basename(file_path)}\"\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error processing IMAGE: {str(e)}\"\n",
    "\n",
    "    # ------------------- YOUTUBE (METADATA-ONLY, NO DOWNLOAD) -------------------\n",
    "    def process_youtube(self, youtube_url):\n",
    "        print(f\"🎥 Processing YouTube link: {youtube_url}\")\n",
    "\n",
    "        ydl_opts = {\n",
    "            'quiet': True,\n",
    "            'skip_download': True,\n",
    "            'extract_flat': True,\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                info = ydl.extract_info(youtube_url, download=False)\n",
    "\n",
    "            video_title = info.get('title', 'Untitled')\n",
    "            uploader = info.get('uploader', 'Unknown')\n",
    "            duration = info.get('duration', 0)\n",
    "            view_count = info.get('view_count', 0)\n",
    "            description = info.get('description', 'No description available.')\n",
    "\n",
    "            print(f\"📹 Title: {video_title}\")\n",
    "            print(f\"👤 Uploader: {uploader}\")\n",
    "            print(f\"⏱ Duration: {duration} seconds\")\n",
    "            print(f\"👁 Views: {view_count:,}\")\n",
    "            print(f\"📝 Description: {description[:200]}...\")\n",
    "\n",
    "            prompt = (\n",
    "                f\"Summarize this YouTube video briefly in 5–6 lines based on the metadata below:\\n\\n\"\n",
    "                f\"Title: {video_title}\\n\"\n",
    "                f\"Uploader: {uploader}\\n\"\n",
    "                f\"Duration: {duration} seconds\\n\"\n",
    "                f\"Views: {view_count}\\n\"\n",
    "                f\"Description: {description[:1000]}\"\n",
    "            )\n",
    "\n",
    "            model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "            response = model.generate_content(prompt)\n",
    "\n",
    "            summary = response.text\n",
    "            db.add(summary, f\"YouTube: {video_title}\")\n",
    "            self.file_count += 1\n",
    "\n",
    "            return (\n",
    "                f\"✅ YouTube video metadata processed successfully!\\n\\n\"\n",
    "                f\"🎬 **Title:** {video_title}\\n\"\n",
    "                f\"👤 **Uploader:** {uploader}\\n\"\n",
    "                f\"⏱ **Duration:** {duration} sec\\n\"\n",
    "                f\"👁 **Views:** {view_count:,}\\n\\n\"\n",
    "                f\"🧠 **Gemini Summary:**\\n{summary}\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error fetching YouTube metadata: {e}\"\n",
    "\n",
    "    # ------------------- QUERY -------------------\n",
    "    def query(self, question):\n",
    "        try:\n",
    "            context = db.get_all_text()\n",
    "            if not context.strip():\n",
    "                return \"❌ No documents loaded yet!\"\n",
    "            \n",
    "            if len(context) > 25000:\n",
    "                context = context[:25000] + \"\\n[truncated...]\"\n",
    "            \n",
    "            prompt = f\"\"\"\n",
    "            Based on the following content, answer the question clearly and concisely.\n",
    "\n",
    "            DOCUMENTS:\n",
    "            {context}\n",
    "\n",
    "            QUESTION: {question}\n",
    "            \"\"\"\n",
    "            \n",
    "            response = model.generate_content(prompt)\n",
    "            return response.text + f\"\\n\\n📚 {len(db.documents)} docs searched.\"\n",
    "        except Exception as e:\n",
    "            return f\"❌ Error during query: {str(e)}\"\n",
    "\n",
    "    # ------------------- MANAGEMENT -------------------\n",
    "    def list_documents(self):\n",
    "        return db.list_all()\n",
    "    \n",
    "    def clear_all(self):\n",
    "        db.clear()\n",
    "        self.file_count = 0\n",
    "        return \"✅ Cleared all data.\"\n",
    "    \n",
    "    def stats(self):\n",
    "        return f\"📊 {len(db.documents)} docs, {len(db.get_all_text()):,} total characters\"\n",
    "\n",
    "# ✅ Create instance\n",
    "processor = MultimodalProcessor()\n",
    "print(\"✅ Processor ready!\")\n",
    "print(\"\\n🎉 SYSTEM READY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c67200dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎥 Processing YouTube video...\n",
      "🎥 Processing YouTube link: https://www.youtube.com/watch?v=M7Q7vzlyPu4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] M7Q7vzlyPu4: nsig extraction failed: Some formats may be missing\n",
      "         n = LSazMBstzC77u9Og ; player = https://www.youtube.com/s/player/c6d7bdc9/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] M7Q7vzlyPu4: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] M7Q7vzlyPu4: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: ffmpeg not found. The downloaded format may not be the best available. Installing ffmpeg is strongly recommended: https://github.com/yt-dlp/yt-dlp#dependencies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📹 Title: 𝐅𝐑𝐄𝐒𝐇𝐄𝐑'𝐒 𝐅𝐫𝐨𝐧𝐭𝐞𝐧𝐝 𝐃𝐞𝐯𝐞𝐥𝐨𝐩𝐞𝐫 𝐈𝐧𝐭𝐞𝐫𝐯𝐢𝐞𝐰 𝐍𝐨-𝟔𝟎 | 𝐉𝐚𝐯𝐚𝐬𝐜𝐫𝐢𝐩𝐭, 𝐑𝐞𝐚𝐜𝐭𝐉𝐒, 𝐇𝐓𝐌𝐋 𝐚𝐧𝐝 𝐂𝐒𝐒\n",
      "👤 Uploader: ReactJS Developer Interview Series \n",
      "⏱ Duration: 1346 seconds\n",
      "👁 Views: 4,575\n",
      "📝 Description: I hope these kind of videos can help you guys while preparing for your upcoming Front end developer interviews.\n",
      "\n",
      "[FULLSTACK INTERVIEW / FRONTEND INTERVIEW / JAVASCRIPT INTERVIEW]\n",
      "Those who want to giv...\n",
      "❌ Error fetching YouTube metadata: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n🎥 Processing YouTube video...\")\n",
    "youtube_url = \"https://www.youtube.com/watch?v=M7Q7vzlyPu4\"\n",
    "result = processor.process_youtube(youtube_url)\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e8ecfad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💬 SAMPLE QUESTIONS:\n",
      "======================================================================\n",
      "\n",
      "❓ What files did I upload?\n",
      "----------------------------------------------------------------------\n",
      "Based on the documents provided, you uploaded the following files:\n",
      "\n",
      "*   **sample.pdf** (Source: sample.pdf)\n",
      "*   **notes.docx** (Source: notes.docx)\n",
      "*   **slides.pptx** (Source: slides.pptx)\n",
      "*   **info.txt** (Source: info.txt)\n",
      "\n",
      "📚 4 docs searched\n",
      "\n",
      "❓ Summarize all content\n",
      "----------------------------------------------------------------------\n",
      "Based on the documents provided, here is a summary of all the content:\n",
      "\n",
      "*   **sample.pdf**: This is a sample PDF file for a \"Multimodal Data Processing System Project\" used for testing purposes.\n",
      "*   **notes.docx**: This is an example Word document created for the project.\n",
      "*   **slides.pptx**: This is an example PowerPoint slide with the title \"Multimodal System.\"\n",
      "*   **info.txt**: This is a sample text file used for testing text extraction functionality.\n",
      "\n",
      "📚 4 docs searched\n",
      "\n",
      "❓ What are the main topics?\n",
      "----------------------------------------------------------------------\n",
      "Based on the documents provided, the main topics are:\n",
      "\n",
      "*   **Multimodal Data Processing System Project**: This is mentioned as the name of the project.\n",
      "    *   **Source**: `sample.pdf`, `slides.pptx`\n",
      "\n",
      "*   **Testing text extraction functionality**: This is mentioned as a specific activity.\n",
      "    *   **Source**: `info.txt`\n",
      "\n",
      "📚 4 docs searched\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELL 6: ASK QUESTIONS\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n💬 SAMPLE QUESTIONS:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "questions = [\n",
    "    \"What files did I upload?\",\n",
    "    \"Summarize all content\",\n",
    "    \"What are the main topics?\",\n",
    "]\n",
    "\n",
    "for q in questions:\n",
    "    print(f\"\\n❓ {q}\")\n",
    "    print(\"-\"*70)\n",
    "    print(processor.query(q))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8693ba9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "🤖 INTERACTIVE MODE\n",
      "Type questions or 'quit' to exit\n",
      "======================================================================\n",
      "\n",
      "Your question: what are the main topics\n",
      "\n",
      "Based on the documents, the main topics are:\n",
      "\n",
      "*   **Multimodal Data Processing System Project**: This is the main project title and subject. (sample.pdf)\n",
      "*   **Multimodal System**: A more general term for the project's subject. (slides.pptx)\n",
      "*   **Testing text extraction functionality**: This is a specific function being tested within the project. (info.txt)\n",
      "\n",
      "📚 4 docs searched\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Your question: exit\n",
      "👋 Goodbye!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\n🤖 INTERACTIVE MODE\")\n",
    "print(\"Type questions or 'quit' to exit\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "while True:\n",
    "    q = input(\"Your question: \")\n",
    "    if q.lower() in ['quit', 'exit', 'q']:\n",
    "        print(\"👋 Goodbye!\")\n",
    "        break\n",
    "    if q.strip():\n",
    "        print(\"\\n\" + processor.query(q) + \"\\n\" + \"-\"*70 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32d71155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎥 Processing YouTube link: https://www.youtube.com/watch?v=RXv_uIN6e-Y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [youtube] Falling back to generic n function search\n",
      "         player = https://www.youtube.com/s/player/87644c66/player_ias.vflset/en_US/base.js\n",
      "WARNING: [youtube] RXv_uIN6e-Y: nsig extraction failed: Some formats may be missing\n",
      "         n = eeGKV-uZ9wdESqPdgq8 ; player = https://www.youtube.com/s/player/87644c66/player_ias.vflset/en_US/base.js\n",
      "         Please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
      "WARNING: [youtube] RXv_uIN6e-Y: Some web_safari client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n",
      "WARNING: [youtube] RXv_uIN6e-Y: Some web client https formats have been skipped as they are missing a url. YouTube is forcing SABR streaming for this client. See  https://github.com/yt-dlp/yt-dlp/issues/12482  for more details\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Error downloading YouTube audio: ERROR: Postprocessing: ffprobe and ffmpeg not found. Please install or provide the path using --ffmpeg-location\n",
      "🧠 Sending audio to Gemini for analysis...\n",
      "📝 Summary:\n",
      "Of course. Here is a brief summary of the YouTube video's main content:\n",
      "\n",
      "This video is a tutorial in Hindi on the \"Top 10 Excel Tricks for Your Interview.\" Using a sample dataset of student scores, the instructor demonstrates several essential Excel formulas and features, explaining their purpose and how to use them.\n",
      "\n",
      "The main topics covered include:\n",
      "\n",
      "*   **Counting Functions:** Explains the difference between `COUNTA` (counts all non-empty cells), `COUNTBLANK` (counts empty cells), and `COUNT` (counts only numbers).\n",
      "*   **Basic Statistical Functions:** Covers `SUM`, `MAX`, `MIN`, and `AVERAGE` to perform basic calculations on the score data.\n",
      "*   **Lookup and Data Retrieval:** Provides a detailed walkthrough of `VLOOKUP` to find a specific student's score from the main table.\n",
      "*   **Conditional Functions:** Demonstrates the \"IF\" family of formulas: `COUNTIF` (count based on criteria, e.g., how many students in a house), `SUMIF` (sum based on criteria), `AVERAGEIF`, and the basic `IF` function (e.g., if the score is 0, then \"Retest\").\n",
      "*   **Text Manipulation:** Shows how to join data using `CONCATENATE` (and the `&` symbol) and how to split data into separate columns using the **Text to Columns** feature.\n",
      "*   **Data Tools & Formatting:** Teaches how to create a **drop-down list** using Data Validation and how to automatically format cells based on their value using **Conditional Formatting**.\n",
      "\n",
      "Overall, the video provides a practical guide to some of the most frequently used and important functions in Excel for data analysis and reporting.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yt_dlp\n",
    "import google.generativeai as genai\n",
    "\n",
    "# ✅ Replace with your valid Gemini model (from earlier cell)\n",
    "YOUTUBE_MODEL = working_model if 'working_model' in locals() else \"models/gemini-2.5-flash\"\n",
    "\n",
    "# ✅ Ask user or set directly\n",
    "youtube_url = \"https://www.youtube.com/watch?v=RXv_uIN6e-Y\"  # <-- replace this with your own link\n",
    "\n",
    "print(f\"🎥 Processing YouTube link: {youtube_url}\")\n",
    "\n",
    "# Download only the audio\n",
    "audio_path = \"youtube_audio.mp3\"\n",
    "\n",
    "ydl_opts = {\n",
    "    'format': 'bestaudio/best',\n",
    "    'outtmpl': audio_path,\n",
    "    'quiet': True,\n",
    "    'postprocessors': [{\n",
    "        'key': 'FFmpegExtractAudio',\n",
    "        'preferredcodec': 'mp3',\n",
    "        'preferredquality': '192',\n",
    "    }],\n",
    "}\n",
    "\n",
    "try:\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([youtube_url])\n",
    "    print(\"✅ Audio downloaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error downloading YouTube audio: {e}\")\n",
    "\n",
    "# Check if file exists before sending to Gemini\n",
    "if os.path.exists(audio_path):\n",
    "    print(\"🧠 Sending audio to Gemini for analysis...\")\n",
    "    try:\n",
    "        model = genai.GenerativeModel(YOUTUBE_MODEL)\n",
    "        response = model.generate_content(\n",
    "            [f\"Summarize the main content of this YouTube video briefly.\", {\"mime_type\": \"audio/mp3\", \"data\": open(audio_path, \"rb\").read()}]\n",
    "        )\n",
    "        print(\"📝 Summary:\")\n",
    "        print(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Gemini processing failed: {e}\")\n",
    "else:\n",
    "    print(\"❌ Audio file not found. Please check the YouTube URL or download settings.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd76c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytube import YouTube\n",
    "\n",
    "def process_youtube(self, url):\n",
    "    try:\n",
    "        if not url.startswith(\"http\"):\n",
    "            return \"❌ Invalid YouTube URL\"\n",
    "        \n",
    "        yt = YouTube(url)\n",
    "        video_title = yt.title\n",
    "        transcript = None\n",
    "        \n",
    "        # Try fetching transcript if available\n",
    "        try:\n",
    "            from youtube_transcript_api import YouTubeTranscriptApi\n",
    "            transcript_data = YouTubeTranscriptApi.get_transcript(yt.video_id)\n",
    "            transcript = \" \".join([x['text'] for x in transcript_data])\n",
    "        except Exception as e:\n",
    "            transcript = \"⚠️ Transcript not available for this video.\"\n",
    "        \n",
    "        db.add(transcript, f\"YouTube: {video_title}\")\n",
    "        self.file_count += 1\n",
    "        return f\"✅ YouTube video processed: {video_title}\"\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"❌ Error fetching YouTube: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b032515e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
